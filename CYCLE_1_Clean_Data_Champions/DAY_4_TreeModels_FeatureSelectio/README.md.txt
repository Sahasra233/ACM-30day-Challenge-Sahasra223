# Day 04 â€“ Tree-Based Models + k-NN + Feature Selection ðŸŒ³ðŸ“Š

## âœ… Tasks Completed:
- Trained three models: Decision Tree, Random Forest, and k-Nearest Neighbors (k-NN)
- Evaluated models using accuracy score and classification report
- Calculated feature importance using Random Forest
- Selected top 3 features based on importance scores
- Retrained models using only the top 3 features
- Compared performance of full model vs 3-feature model

## ðŸ“Š Key Insights:
- Feature selection can reduce model complexity while retaining reasonable accuracy
- Random Forest provided the best feature importance rankings
- The top 3 features identified were: `stresslevel`, `worklifebalancescore`, and `managersupportscore` (example â€” yours may vary)
- Slight drop in performance was observed with reduced features, but model became faster and more interpretable

